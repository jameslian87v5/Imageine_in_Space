# Imageine_in_Space

Humans exhibit dual-channel behavior in visual and spatial reasoning. However, current multimodal models (VLMs) still demonstrate limited capabilities in both spatial and visual reasoning. This gap arises from the misalignment between existing multimodal training pipelines and the way humans learn. To emulate human visual reasoning abilities, we have developed a training approach focused on enhancing visual imagination and reasoning, and plan to leverage the InternVL 2.5 model to strengthen these capabilities.
